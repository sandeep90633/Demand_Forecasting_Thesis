{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b96fcf14-dc99-4679-9e7c-fce2563993da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81bc8aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name ='original_sales_data.csv'\n",
    "\n",
    "try:\n",
    "    sales = pd.read_csv(r\"C:\\Users\\JASWANTH REDDY\\OneDrive\\Desktop\\Projects\\Demand_Forecasting_Thesis\\data\\original_sales_data.csv\")\n",
    "except:\n",
    "    print(\"Provided file name not found in the local, downloading from s3 bucket....\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4300094a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_date</th>\n",
       "      <th>sku_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>order_quantity</th>\n",
       "      <th>unit_sale_price</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SO - 018900</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>3551CA</td>\n",
       "      <td>GUT930</td>\n",
       "      <td>Export</td>\n",
       "      <td>105.00</td>\n",
       "      <td>7.07</td>\n",
       "      <td>742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SO - 018901</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>3079BA</td>\n",
       "      <td>AXW291</td>\n",
       "      <td>Wholesale</td>\n",
       "      <td>151.00</td>\n",
       "      <td>134.50</td>\n",
       "      <td>20310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SO - 018902</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>3250CA</td>\n",
       "      <td>AXW291</td>\n",
       "      <td>Distributor</td>\n",
       "      <td>300.00</td>\n",
       "      <td>34.75</td>\n",
       "      <td>10426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SO - 018903</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>1161AA</td>\n",
       "      <td>GUT930</td>\n",
       "      <td>Wholesale</td>\n",
       "      <td>50.00</td>\n",
       "      <td>136.59</td>\n",
       "      <td>6830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SO - 018904</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>3512AA</td>\n",
       "      <td>GUT930</td>\n",
       "      <td>Distributor</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  order_number  order_date  sku_id warehouse_id customer_type  order_quantity  \\\n",
       "0   SO - 018900 2021-01-01  3551CA       GUT930        Export          105.00   \n",
       "1   SO - 018901 2021-01-01  3079BA       AXW291     Wholesale          151.00   \n",
       "2   SO - 018902 2021-01-01  3250CA       AXW291   Distributor          300.00   \n",
       "3   SO - 018903 2021-01-01  1161AA       GUT930     Wholesale           50.00   \n",
       "4   SO - 018904 2021-01-01  3512AA       GUT930   Distributor         1000.00   \n",
       "\n",
       "   unit_sale_price  revenue  \n",
       "0             7.07      742  \n",
       "1           134.50    20310  \n",
       "2            34.75    10426  \n",
       "3           136.59     6830  \n",
       "4             0.10      103  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51b95b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sales.loc[:, ~sales.columns.str.startswith('Unnamed')]\n",
    "\n",
    "df['order_date'] = pd.to_datetime(df['order_date'], format='%d-%b-%y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4c4c66",
   "metadata": {},
   "source": [
    "Aggregate quantity by sku_id per each a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7b093e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_per_type_wh_daily_sales = df.groupby(['order_date', 'sku_id'])['order_quantity'].sum().reset_index()\n",
    "\n",
    "sku_per_type_wh_daily_sales = sku_per_type_wh_daily_sales.sort_values(by=['sku_id', 'order_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b218bc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 33299 entries, 39 to 33118\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   order_date          33299 non-null  datetime64[ns]\n",
      " 1   sku_id              33299 non-null  object        \n",
      " 2   customer_type       33299 non-null  object        \n",
      " 3   warehouse_id        33299 non-null  object        \n",
      " 4   order_quantity      33299 non-null  float64       \n",
      " 5   lag_1               30155 non-null  float64       \n",
      " 6   lag_7               17105 non-null  float64       \n",
      " 7   rolling_avg_7_days  18751 non-null  float64       \n",
      " 8   cumulative_sum      33299 non-null  float64       \n",
      " 9   year                33299 non-null  int32         \n",
      " 10  month               33299 non-null  int32         \n",
      " 11  day_of_week         33299 non-null  int32         \n",
      "dtypes: datetime64[ns](1), float64(5), int32(3), object(3)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "sku_per_type_wh_daily_sales.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440de1e2",
   "metadata": {},
   "source": [
    "Feature Engineering to feed model with extra features for more accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b79ee1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_per_type_wh_daily_sales['lag_1'] = sku_per_type_wh_daily_sales.groupby('sku_id')['order_quantity'].shift(1)\n",
    "sku_per_type_wh_daily_sales['lag_7'] = sku_per_type_wh_daily_sales.groupby('sku_id')['order_quantity'].shift(7)\n",
    "sku_per_type_wh_daily_sales['rolling_avg_7_days'] = sku_per_type_wh_daily_sales.groupby('sku_id')['order_quantity'].transform(lambda x: x.rolling(window=7).mean())\n",
    "sku_per_type_wh_daily_sales['cumulative_sum'] = sku_per_type_wh_daily_sales.groupby('sku_id')['order_quantity'].cumsum()\n",
    "sku_per_type_wh_daily_sales['year'] = sku_per_type_wh_daily_sales['order_date'].dt.year\n",
    "sku_per_type_wh_daily_sales['month'] = sku_per_type_wh_daily_sales['order_date'].dt.month\n",
    "sku_per_type_wh_daily_sales['day_of_week'] = sku_per_type_wh_daily_sales['order_date'].dt.dayofweek\n",
    "sku_per_type_wh_daily_sales['week'] = sku_per_type_wh_daily_sales['order_date'].dt.isocalendar().week\n",
    "# Removing events that have NaN values\n",
    "sku_daily_sales = sku_per_type_wh_daily_sales.dropna(subset=['lag_1', 'lag_7', 'rolling_avg_7_days', 'cumulative_sum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4435a0",
   "metadata": {},
   "source": [
    "Spliting data: 80% as train data and 20% as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "deac579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date_filtered = sku_daily_sales['order_date'].quantile(0.8)\n",
    "train_data_filtered = sku_daily_sales[sku_daily_sales['order_date'] <= split_date_filtered]\n",
    "test_data_filtered = sku_daily_sales[sku_daily_sales['order_date'] > split_date_filtered]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e59426",
   "metadata": {},
   "source": [
    "Drop order_date as we captured everything from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b11b510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_filtered.drop(columns='order_date', inplace=True)\n",
    "test_data_filtered.drop(columns='order_date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670b9cb6",
   "metadata": {},
   "source": [
    "This function convert object data type categorical columns into integer type columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0c94b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncoding(df, index_column):\n",
    "    df=df.set_index(index_column)\n",
    "    \n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    one_hot_encoded_categorical = encoder.fit_transform(df[categorical_cols])\n",
    "    one_hot_df = pd.DataFrame(one_hot_encoded_categorical, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "    \n",
    "    one_hot_encoded = pd.concat([df.reset_index(),one_hot_df], axis=1)\n",
    "    one_hot_encoded = one_hot_encoded.drop(categorical_cols, axis=1)\n",
    "    df = one_hot_encoded.set_index(index_column)\n",
    "\n",
    "    return df\n",
    "\n",
    "train_data_filtered = oneHotEncoding(train_data_filtered, 'sku_id')\n",
    "test_data_filtered = oneHotEncoding(test_data_filtered, 'sku_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03952bb9",
   "metadata": {},
   "source": [
    "Separate features and target for sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f22ecd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_original = train_data_filtered.iloc[:,1:]\n",
    "y_train_original = train_data_filtered['order_quantity']\n",
    "X_test_original = test_data_filtered.iloc[:,1:]\n",
    "y_test_original = test_data_filtered['order_quantity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d02a625",
   "metadata": {},
   "source": [
    "Fine tuning the model to get the most suitable hyperparameters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10204ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 240 candidates, totalling 720 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 250}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyperparameter grid to fine tune for Random Forest Model\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200, 250, 300],\n",
    "    'max_depth': [5, 10, 20, None],\n",
    "    'min_samples_split': [2,5,7,10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Random Forest model \n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Perform Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train_original, y_train_original)\n",
    "\n",
    "# Best parameters and performance\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3141f196",
   "metadata": {},
   "source": [
    "({'max_depth': 10,\n",
    "  'min_samples_leaf': 2,\n",
    "  'min_samples_split': 10,\n",
    "  'n_estimators': 300},\n",
    " np.float64(3169267.57223538))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c17cae62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(2600842.9805036364),\n",
       " np.float64(1612.7129256329647),\n",
       " 0.6357431970409999)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Random Forest model\n",
    "rf_model = RandomForestRegressor(random_state=42, n_estimators=250, max_depth=5, min_samples_leaf=2, min_samples_split=10)\n",
    "rf_model.fit(X_train_original, y_train_original)\n",
    "\n",
    "# Predict on the test set\n",
    "rf_predictions = rf_model.predict(X_test_original)\n",
    "\n",
    "# Evaluate the model\n",
    "rf_mse = mean_squared_error(y_test_original, rf_predictions)\n",
    "rf_rmse = np.sqrt(rf_mse)\n",
    "rf_r2 = r2_score(y_test_original, rf_predictions)\n",
    "\n",
    "rf_mse, rf_rmse, rf_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a39c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'subsample': 1.0,\n",
       "  'n_estimators': 100,\n",
       "  'max_depth': 2,\n",
       "  'learning_rate': 0.2,\n",
       "  'gamma': 1,\n",
       "  'colsample_bytree': 0.6},\n",
       " np.float64(3140223.3115354306))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Define the hyperparameter grid for XGBoost\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200, 300, 400],          # Number of boosting rounds\n",
    "    'max_depth': [2, 3, 5, 7, 10],                   # Maximum tree depth\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],      # Step size for weight updates\n",
    "    'subsample': [0.6, 0.8, 1.0],                 # Fraction of samples used for training each tree\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],          # Fraction of features considered for each split\n",
    "    'gamma': [0, 1, 5]                            # Minimum loss reduction required to make a split\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = XGBRegressor(random_state=42, objective='reg:squarederror')\n",
    "\n",
    "# Perform Randomized Search with cross-validation\n",
    "random_search_xgb = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_grid_xgb,\n",
    "    n_iter=50,  # Number of parameter combinations to try\n",
    "    cv=3,       # 3-fold cross-validation\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search_xgb.fit(X_train_original, y_train_original)\n",
    "\n",
    "# Best parameters and performance\n",
    "best_params_xgb = random_search_xgb.best_params_\n",
    "best_score_xgb = -random_search_xgb.best_score_  # Convert from negative MSE to MSE\n",
    "\n",
    "best_params_xgb, best_score_xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2244fcd9",
   "metadata": {},
   "source": [
    "({'subsample': 0.8,\n",
    "  'n_estimators': 200,\n",
    "  'max_depth': 3,\n",
    "  'learning_rate': 0.05,\n",
    "  'gamma': 0,\n",
    "  'colsample_bytree': 0.8},\n",
    " np.float64(3222520.287230836))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "802470ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(2846917.1009056633),\n",
       " np.float64(1687.2809786474993),\n",
       " 0.6012796892243022)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model_original = XGBRegressor(random_state=42, n_estimators=100, learning_rate=0.2, subsample=1.0, max_depth= 2, gamma= 1, colsample_bytree=0.6)\n",
    "xgb_model_original.fit(X_train_original, y_train_original)\n",
    "\n",
    "# Predict on the test set\n",
    "xgb_predictions_original_scale = xgb_model_original.predict(X_test_original)\n",
    "\n",
    "# Evaluate the XGBoost model in the original scale\n",
    "xgb_mse_no_log = mean_squared_error(y_test_original, xgb_predictions_original_scale)\n",
    "xgb_rmse_no_log = np.sqrt(xgb_mse_no_log)\n",
    "xgb_r2_no_log = r2_score(y_test_original, xgb_predictions_original_scale)\n",
    "\n",
    "xgb_mse_no_log, xgb_rmse_no_log, xgb_r2_no_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4886de8-104f-4baa-9af2-0b42eaa83eff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
